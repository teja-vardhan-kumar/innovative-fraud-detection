{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare the real-time scoring model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The team at Woodgrove Bank has provided you with exported CSV copies of historical data for you to train your model against. Run the following cell to load required libraries and download the data sets from the Azure ML datastore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade azureml-train-automl-runtime==1.36.0\n",
        "#!pip install --upgrade azureml-automl-runtime==1.36.0\n",
        "#!pip install --upgrade scikit-learn\n",
        "#!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613511718401
        },
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\catnip\\AppData\\Local\\Temp\\ipykernel_8320\\3964955863.py:17: DtypeWarning: Columns (6,9,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  account_df = pd.read_csv('./data/Account_Info.csv')\n",
            "C:\\Users\\catnip\\AppData\\Local\\Temp\\ipykernel_8320\\3964955863.py:19: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  untagged_df = pd.read_csv( './data/Untagged_Transactions.csv')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# sklearn.externals.joblib was deprecated in 0.21\n",
        "from sklearn import __version__ as sklearnver\n",
        "from packaging.version import Version\n",
        "if Version(sklearnver) < Version(\"0.21.0\"):\n",
        "    from sklearn.externals import joblib\n",
        "else:\n",
        "    import joblib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "account_df = pd.read_csv('./data/Account_Info.csv')\n",
        "fraud_df = pd.read_csv('./data/Fraud_Transactions.csv')\n",
        "untagged_df = pd.read_csv( './data/Untagged_Transactions.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the fraud dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1613511718572
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transactionID</th>\n",
              "      <th>accountID</th>\n",
              "      <th>transactionAmount</th>\n",
              "      <th>transactionCurrencyCode</th>\n",
              "      <th>transactionDate</th>\n",
              "      <th>transactionTime</th>\n",
              "      <th>localHour</th>\n",
              "      <th>transactionDeviceId</th>\n",
              "      <th>transactionIPaddress</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65020E58-781D-4FFC-BEF2-0FDF87BE671D</td>\n",
              "      <td>A985156981092344</td>\n",
              "      <td>1148.60</td>\n",
              "      <td>CAD</td>\n",
              "      <td>20130402</td>\n",
              "      <td>14450</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>66.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8EC10EBC-F4BB-4148-9073-4B2BA93C9B34</td>\n",
              "      <td>A985156981066925</td>\n",
              "      <td>150.31</td>\n",
              "      <td>USD</td>\n",
              "      <td>20130403</td>\n",
              "      <td>135015</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CD624353-E473-4EE0-8BDF-A818627AA1D1</td>\n",
              "      <td>A985156970845915</td>\n",
              "      <td>99.98</td>\n",
              "      <td>USD</td>\n",
              "      <td>20130403</td>\n",
              "      <td>161950</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          transactionID         accountID  transactionAmount  \\\n",
              "0  65020E58-781D-4FFC-BEF2-0FDF87BE671D  A985156981092344            1148.60   \n",
              "1  8EC10EBC-F4BB-4148-9073-4B2BA93C9B34  A985156981066925             150.31   \n",
              "2  CD624353-E473-4EE0-8BDF-A818627AA1D1  A985156970845915              99.98   \n",
              "\n",
              "  transactionCurrencyCode  transactionDate  transactionTime  localHour  \\\n",
              "0                     CAD         20130402            14450       20.0   \n",
              "1                     USD         20130403           135015        8.0   \n",
              "2                     USD         20130403           161950       11.0   \n",
              "\n",
              "   transactionDeviceId  transactionIPaddress  \n",
              "0                  NaN                 66.46  \n",
              "1                  NaN                 67.80  \n",
              "2                  NaN                 96.57  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fraud_df.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the account info dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1613511718776
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accountID</th>\n",
              "      <th>transactionDate</th>\n",
              "      <th>transactionTime</th>\n",
              "      <th>accountOwnerName</th>\n",
              "      <th>accountAddress</th>\n",
              "      <th>accountPostalCode</th>\n",
              "      <th>accountCity</th>\n",
              "      <th>accountState</th>\n",
              "      <th>accountCountry</th>\n",
              "      <th>accountOpenDate</th>\n",
              "      <th>accountAge</th>\n",
              "      <th>isUserRegistered</th>\n",
              "      <th>paymentInstrumentAgeInAccount</th>\n",
              "      <th>numPaymentRejects1dPerUser</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1688852564389340</td>\n",
              "      <td>20130401</td>\n",
              "      <td>2932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30170-000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MG</td>\n",
              "      <td>BR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A985156162171434</td>\n",
              "      <td>20130401</td>\n",
              "      <td>3005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>da11 9ps</td>\n",
              "      <td>NaN</td>\n",
              "      <td>England</td>\n",
              "      <td>GB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61.0</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>55.490972</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A844427191626038</td>\n",
              "      <td>20130401</td>\n",
              "      <td>12302</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4671</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Queensland</td>\n",
              "      <td>AU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           accountID  transactionDate  transactionTime  accountOwnerName  \\\n",
              "0  A1688852564389340         20130401             2932               NaN   \n",
              "1   A985156162171434         20130401             3005               NaN   \n",
              "2   A844427191626038         20130401            12302               NaN   \n",
              "\n",
              "   accountAddress accountPostalCode accountCity accountState accountCountry  \\\n",
              "0             NaN         30170-000         NaN           MG             BR   \n",
              "1             NaN          da11 9ps         NaN      England             GB   \n",
              "2             NaN              4671         NaN   Queensland             AU   \n",
              "\n",
              "  accountOpenDate  accountAge isUserRegistered paymentInstrumentAgeInAccount  \\\n",
              "0             NaN         1.0            FALSE                      0.000694   \n",
              "1             NaN        61.0             TRUE                     55.490972   \n",
              "2             NaN         1.0            FALSE                      0.002083   \n",
              "\n",
              "   numPaymentRejects1dPerUser  \n",
              "0                         0.0  \n",
              "1                         0.0  \n",
              "2                         0.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "account_df.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the untagged transactions dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1613511718973
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accountID</th>\n",
              "      <th>browserLanguage</th>\n",
              "      <th>browserType</th>\n",
              "      <th>cardNumberInputMethod</th>\n",
              "      <th>cardType</th>\n",
              "      <th>cvvVerifyResult</th>\n",
              "      <th>digitalItemCount</th>\n",
              "      <th>ipCountryCode</th>\n",
              "      <th>ipPostcode</th>\n",
              "      <th>ipState</th>\n",
              "      <th>...</th>\n",
              "      <th>transactionCurrencyConversionRate</th>\n",
              "      <th>transactionDate</th>\n",
              "      <th>transactionDeviceId</th>\n",
              "      <th>transactionDeviceType</th>\n",
              "      <th>transactionID</th>\n",
              "      <th>transactionIPaddress</th>\n",
              "      <th>transactionMethod</th>\n",
              "      <th>transactionScenario</th>\n",
              "      <th>transactionTime</th>\n",
              "      <th>transactionType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A985156985579195</td>\n",
              "      <td>en-AU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VISA</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>au</td>\n",
              "      <td>3000</td>\n",
              "      <td>victoria</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20130409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5EAC1EBD-1428-4593-898E-F4B56BC3FA06</td>\n",
              "      <td>121.219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>95040</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A985156966855837</td>\n",
              "      <td>en-AU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VISA</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>us</td>\n",
              "      <td>14534</td>\n",
              "      <td>new york</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20130409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48C88D1C-3705-472B-A4A3-5FCE45A5429B</td>\n",
              "      <td>216.150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>94256</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A844428012992486</td>\n",
              "      <td>nn-NO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MC</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>1006</td>\n",
              "      <td>oslo</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20130409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13B2A110-EA04-42CD-88CC-A85814A5C961</td>\n",
              "      <td>94.246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>95257</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          accountID browserLanguage  browserType  cardNumberInputMethod  \\\n",
              "0  A985156985579195           en-AU          NaN                    NaN   \n",
              "1  A985156966855837           en-AU          NaN                    NaN   \n",
              "2  A844428012992486           nn-NO          NaN                    NaN   \n",
              "\n",
              "  cardType cvvVerifyResult  digitalItemCount ipCountryCode ipPostcode  \\\n",
              "0     VISA               M                 1            au       3000   \n",
              "1     VISA               M                 0            us      14534   \n",
              "2       MC               M                 1            no       1006   \n",
              "\n",
              "    ipState  ... transactionCurrencyConversionRate  transactionDate  \\\n",
              "0  victoria  ...                               NaN         20130409   \n",
              "1  new york  ...                               NaN         20130409   \n",
              "2      oslo  ...                               NaN         20130409   \n",
              "\n",
              "   transactionDeviceId transactionDeviceType  \\\n",
              "0                  NaN                   NaN   \n",
              "1                  NaN                   NaN   \n",
              "2                  NaN                   NaN   \n",
              "\n",
              "                          transactionID transactionIPaddress  \\\n",
              "0  5EAC1EBD-1428-4593-898E-F4B56BC3FA06              121.219   \n",
              "1  48C88D1C-3705-472B-A4A3-5FCE45A5429B              216.150   \n",
              "2  13B2A110-EA04-42CD-88CC-A85814A5C961               94.246   \n",
              "\n",
              "  transactionMethod  transactionScenario transactionTime  transactionType  \n",
              "0               NaN                    A           95040                P  \n",
              "1               NaN                    A           94256                P  \n",
              "2               NaN                    A           95257                P  \n",
              "\n",
              "[3 rows x 40 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "###### Reorder the column of dataframe by ascending order in pandas \n",
        "cols=untagged_df.columns.tolist()\n",
        "cols.sort()\n",
        "untagged_df=untagged_df[cols]\n",
        "\n",
        "untagged_df.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare data\n",
        "\n",
        "The raw data has some issues we need to cleanup before we can use it to train a model, which we perform in the following cells."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare accounts\n",
        "\n",
        "Begin by cleaning the data in accounts data set.\n",
        "Remove columns that have very few or no values: `accountOwnerName`, `accountAddress`, `accountCity` and `accountOpenDate` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1613511719101
        }
      },
      "outputs": [],
      "source": [
        "account_df_clean = account_df[[\"accountID\", \"transactionDate\", \"transactionTime\", \n",
        "                               \"accountPostalCode\", \"accountState\", \"accountCountry\", \n",
        "                               \"accountAge\", \"isUserRegistered\", \"paymentInstrumentAgeInAccount\", \n",
        "                               \"numPaymentRejects1dPerUser\"]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a copy of the dataframe so our data manipulation does not affect the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1613511719240
        }
      },
      "outputs": [],
      "source": [
        "account_df_clean = account_df_clean.copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's ensure that values that are not numeric (e.g., they have incorrect string values or garbage data) are converted to NaN and then we can fill those NaN values with 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1613511719390
        }
      },
      "outputs": [],
      "source": [
        "account_df_clean['paymentInstrumentAgeInAccount'] = pd.to_numeric(account_df_clean['paymentInstrumentAgeInAccount'], errors='coerce')\n",
        "account_df_clean['paymentInstrumentAgeInAccount'] = account_df_clean[['paymentInstrumentAgeInAccount']].fillna(0)['paymentInstrumentAgeInAccount']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's convert the `numPaymentRejects1dPerUser` so that the column has a datatype of `float` instead of `object`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1613511719499
        }
      },
      "outputs": [],
      "source": [
        "account_df_clean[\"numPaymentRejects1dPerUser\"] = account_df_clean[[\"numPaymentRejects1dPerUser\"]].astype(float)[\"numPaymentRejects1dPerUser\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1613511719630
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numPaymentRejects1dPerUser\n",
              "0.0     191382\n",
              "1.0       5500\n",
              "2.0       1476\n",
              "3.0        562\n",
              "4.0        254\n",
              "5.0        136\n",
              "6.0         51\n",
              "7.0         30\n",
              "8.0         27\n",
              "10.0        24\n",
              "9.0         14\n",
              "17.0         9\n",
              "14.0         6\n",
              "13.0         4\n",
              "16.0         3\n",
              "32.0         2\n",
              "12.0         2\n",
              "11.0         2\n",
              "15.0         1\n",
              "23.0         1\n",
              "18.0         1\n",
              "26.0         1\n",
              "28.0         1\n",
              "29.0         1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "account_df_clean[\"numPaymentRejects1dPerUser\"].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`account_df_clean` is now ready for use in modeling."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare untagged transactions\n",
        "\n",
        "Next, cleanup the untagged transactions data set. There are 16 columns in the untagged_transactions whose values are all null, let's drop these columns to simplify our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1613511719849
        }
      },
      "outputs": [],
      "source": [
        "untagged_df_clean = untagged_df.dropna(axis=1, how=\"all\").copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can examine the count of non-null values, and view the inferred data type for each column by running the following cell. Looking at the output of the cell, we have some work to do. For a start, we have columns with fewer than 200,000 non-null values. This means there are some null values in that column that we need to fix."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's cleanup the `localHour` field. \n",
        "\n",
        "Replace null values in `localHour` with `-99`. Also replace values of `-1` with `-99`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1613511720100
        }
      },
      "outputs": [],
      "source": [
        "untagged_df_clean[\"localHour\"] = untagged_df_clean[\"localHour\"].fillna(-99)\n",
        "untagged_df_clean.loc[untagged_df_clean.loc[:,\"localHour\"] == -1, \"localHour\"] = -99"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the values now look good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1613511720219
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "localHour\n",
              " 13.0    12783\n",
              " 15.0    12720\n",
              " 14.0    12694\n",
              " 10.0    12439\n",
              " 11.0    12372\n",
              " 12.0    12315\n",
              " 16.0    11929\n",
              " 19.0    11880\n",
              " 20.0    11588\n",
              " 18.0    11539\n",
              " 17.0    11458\n",
              " 9.0     11200\n",
              " 21.0     9728\n",
              " 8.0      8768\n",
              "-99.0     7037\n",
              " 22.0     6986\n",
              " 7.0      5368\n",
              " 23.0     4716\n",
              " 6.0      3094\n",
              " 0.0      2944\n",
              " 1.0      1859\n",
              " 5.0      1596\n",
              " 2.0      1122\n",
              " 4.0       969\n",
              " 3.0       896\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "untagged_df_clean[\"localHour\"].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean up the remaining null fields:\n",
        "- Fix missing values for location fields by setting them to `NA` for unknown. \n",
        "- Set `isProxyIP` to False\n",
        "- Set `cardType` to `U` for unknown (which is a new level)\n",
        "- Set `cvvVerifyResult` to `N` which means for those where the transaction failed because the wrong CVV2 number was entered ro no CVV2 numebr was entered, treat those as if there was no CVV2 match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1613511720330
        }
      },
      "outputs": [],
      "source": [
        "untagged_df_clean = untagged_df_clean.fillna(value={\"ipState\": \"NA\", \"ipPostcode\": \"NA\", \"ipCountryCode\": \"NA\", \n",
        "                               \"isProxyIP\":False, \"cardType\": \"U\", \n",
        "                               \"paymentBillingPostalCode\" : \"NA\", \"paymentBillingState\":\"NA\",\n",
        "                               \"paymentBillingCountryCode\" : \"NA\", \"cvvVerifyResult\": \"N\"\n",
        "                              })"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm all null values have been addressed."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `transactionScenario` column provides no insights because all rows have the same `A` value. Let's drop that column. Same idea for the `transactionType` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1613511720628
        }
      },
      "outputs": [],
      "source": [
        "del untagged_df_clean[\"transactionScenario\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1613511720733
        }
      },
      "outputs": [],
      "source": [
        "del untagged_df_clean[\"transactionType\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`untagged_df_clean` is now ready for use in modeling."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare fraud transactions\n",
        "\n",
        "Now move on to preparing the fraud transactions data set.\n",
        "\n",
        "The `transactionDeviceId` has no meaningful values, so we will drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1613511720840
        }
      },
      "outputs": [],
      "source": [
        "fraud_df_clean = fraud_df.copy()\n",
        "del fraud_df_clean['transactionDeviceId']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fraud data set has a `localHour` field that we need to fill missing values, just as we did for the account data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1613511721027
        }
      },
      "outputs": [],
      "source": [
        "fraud_df_clean[\"localHour\"] = fraud_df_clean[\"localHour\"].fillna(-99)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine your work, you should have 8640 non-null values in each column."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`fraud_df_clean` is now ready for use in modeling."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create labels\n",
        "\n",
        "The goal is to create a dataframe with all transactions, where each transaction is tagged via the `isFraud` column with a value of `0` - no fraud or `1` - fraudulent. \n",
        "\n",
        "Any transactions that appear in untagged_transactions dataframe that also appear in the fraud dataframe will be marked as fraudulent. \n",
        "\n",
        "The remaining transactions will be marked as not fraudulent. \n",
        "\n",
        "Run the following cells to create the labels series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1613511721246
        }
      },
      "outputs": [],
      "source": [
        "all_labels = untagged_df_clean[\"transactionID\"].isin(fraud_df_clean[\"transactionID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1613511721358
        }
      },
      "outputs": [],
      "source": [
        "all_transactions = untagged_df_clean"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we can save our estimators module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1613511721585
        }
      },
      "outputs": [],
      "source": [
        "# write out to models/customestimators.py\n",
        "scoring_service = \"\"\"\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class NumericCleaner(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self = self\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"NumericCleaner.fit called\")\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        print(\"NumericCleaner.transform called\")\n",
        "        X[\"localHour\"] = X[\"localHour\"].fillna(-99)\n",
        "        X.loc[X.loc[:,\"localHour\"] == -1, \"localHour\"] = -99\n",
        "        return X\n",
        "\n",
        "class CategoricalCleaner(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self = self\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"CategoricalCleaner.fit called\")\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        print(\"CategoricalCleaner.transform called\")\n",
        "        X = X.fillna(value={\"cardType\":\"U\",\"cvvVerifyResult\": \"N\"})\n",
        "        return X\n",
        "\"\"\" \n",
        "\n",
        "with open(\"./customestimators.py\", \"w\") as file:\n",
        "    file.write(scoring_service)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, load the estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1613511721824
        }
      },
      "outputs": [],
      "source": [
        "from customestimators import NumericCleaner, CategoricalCleaner"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now build the pipeline that will prepare the data. \n",
        "\n",
        "The gist of the following cell is to split the data preparation into two paths, splitting the data sets vertically, and then combine the result. The `ColumnTransformer` will effectively concatenate the data frame that results from the numeric transformations with the data frame resulting from the categorical transformations. \n",
        "\n",
        "- Numeric Transformer Pipeline: We use the custom transformers created previously to cleanup the numeric columns. Since the model you will train in this notebook is a Support Vector Machine classifier, we need to standardize the scale of numeric values which is what the `StandardScaler` provides.\n",
        "- Categorical Transformer Pipeline: We use the custome transformer created previously cleanup the categorical columns. Then we one-hot encode each value of each categorical column, resulting in a wider data frame with one column for each possible value (and 1 appearing in rows that had that value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1613511721941
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "numeric_features=[\"transactionAmountUSD\", \"transactionDate\", \"transactionTime\", \"localHour\", \n",
        "                  \"transactionIPaddress\", \"digitalItemCount\", \"physicalItemCount\"]\n",
        "\n",
        "categorical_features=[\"transactionCurrencyCode\", \"browserLanguage\", \"paymentInstrumentType\", \"cardType\", \"cvvVerifyResult\"]                           \n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('cleaner', NumericCleaner()),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "                               \n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('cleaner', CategoricalCleaner()),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's confirm we run all our historical data thru this transformation pipeline and observe the resulting shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1613511722317
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.fit called\n",
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.fit called\n",
            "CategoricalCleaner.transform called\n"
          ]
        }
      ],
      "source": [
        "preprocessed_result = preprocessor.fit_transform(all_transactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1613511722445
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000, 292)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1613511722575
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.152051</td>\n",
              "      <td>-1.422822</td>\n",
              "      <td>-0.516830</td>\n",
              "      <td>0.417653</td>\n",
              "      <td>0.265748</td>\n",
              "      <td>0.218614</td>\n",
              "      <td>-0.357016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.555361</td>\n",
              "      <td>-1.422822</td>\n",
              "      <td>-0.527675</td>\n",
              "      <td>-5.086697</td>\n",
              "      <td>1.964129</td>\n",
              "      <td>-1.403816</td>\n",
              "      <td>0.593898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.039733</td>\n",
              "      <td>-1.422822</td>\n",
              "      <td>-0.513828</td>\n",
              "      <td>-0.002170</td>\n",
              "      <td>-0.216818</td>\n",
              "      <td>0.218614</td>\n",
              "      <td>-0.357016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.533650</td>\n",
              "      <td>-1.422822</td>\n",
              "      <td>-0.407303</td>\n",
              "      <td>0.184418</td>\n",
              "      <td>-0.239646</td>\n",
              "      <td>-1.403816</td>\n",
              "      <td>3.446637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.150220</td>\n",
              "      <td>-1.422822</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.044477</td>\n",
              "      <td>-0.199231</td>\n",
              "      <td>0.218614</td>\n",
              "      <td>-0.357016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 292 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    7    \\\n",
              "0 -0.152051 -1.422822 -0.516830  0.417653  0.265748  0.218614 -0.357016  0.0   \n",
              "1  0.555361 -1.422822 -0.527675 -5.086697  1.964129 -1.403816  0.593898  0.0   \n",
              "2 -0.039733 -1.422822 -0.513828 -0.002170 -0.216818  0.218614 -0.357016  0.0   \n",
              "3  2.533650 -1.422822 -0.407303  0.184418 -0.239646 -1.403816  3.446637  0.0   \n",
              "4  0.150220 -1.422822 -0.399612  0.044477 -0.199231  0.218614 -0.357016  0.0   \n",
              "\n",
              "   8    9    ...  282  283  284  285  286  287  288  289  290  291  \n",
              "0  1.0  0.0  ...  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  1.0  0.0  ...  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  0.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3  0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 292 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(preprocessed_result.todense()).head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create pipeline and train a simple model\n",
        "\n",
        "Now you will build upon the transformation pipeline you created previously to train a model to classify rows as fraudulent or not fraudulent.\n",
        "\n",
        "Run the following cells to make sure you've imported the dependencies for the pipeline (you probably already have, but having them clearly loaded here will help you when porting your code to a web service)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1613511722677
        }
      },
      "outputs": [],
      "source": [
        "from customestimators import NumericCleaner, CategoricalCleaner\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As might be obvious, our data has a lot of samples that are not fraudulent. If we proceed to train a model, we will effectively train the model to predict non-fraud. This situation where one class (non-fraud) appears much more often than the others (fraud) is called a class imbalance, and to mitigate its effect we can reduce the number of non-fraud samples so that we have the same number of non-fraud and fraud samples. \n",
        "\n",
        "Run the following cells to downsize and then randomly sample 1,151 non-fraud rows, and then we'll union these row with our 1,151 fraud rows.\n",
        "\n",
        "> Feel free to ignore any `SettingWithCopyWarning` warnings in the cell output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1613511722943
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\catnip\\AppData\\Local\\Temp\\ipykernel_8320\\3537884859.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  only_fraud_samples[\"label\"] = True\n",
            "C:\\Users\\catnip\\AppData\\Local\\Temp\\ipykernel_8320\\3537884859.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  only_non_fraud_samples[\"label\"] = False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "label\n",
              "False    1151\n",
              "True     1151\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "only_fraud_samples = all_transactions.loc[all_labels == True]\n",
        "only_fraud_samples[\"label\"] = True\n",
        "only_non_fraud_samples = all_transactions.loc[all_labels == False]\n",
        "only_non_fraud_samples[\"label\"] = False\n",
        "random_non_fraud_samples = only_non_fraud_samples.sample(n=1151, replace=False, random_state=42)\n",
        "balanced_transactions = pd.concat([random_non_fraud_samples, only_fraud_samples])\n",
        "\n",
        "balanced_transactions[\"label\"].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, you need to separate out the label column from the dataframe so the labels are not used as input features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1613511723055
        }
      },
      "outputs": [],
      "source": [
        "balanced_labels = balanced_transactions[\"label\"]\n",
        "del balanced_transactions[\"label\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you will create subsets of the training data frame, one that will be used for training the model `X_train` and `y_train` and the another that reserved for testing its performance `X_test` and `y_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1613511723155
        }
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(balanced_transactions, balanced_labels, \n",
        "                                                    test_size=0.2, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now train the model. In this case, you will use the `LinearSVC` class.\n",
        "\n",
        "> Feel free to ignore any `ConvergenceWarning` warnings in the cell output below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1613511723343
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.fit called\n",
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.fit called\n",
            "CategoricalCleaner.transform called\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\catnip\\Desktop\\Projects_imp\\Data_Engineer\\Fraud_detection\\model\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
              "                                                                   NumericCleaner()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;transactionAmountUSD&#x27;,\n",
              "                                                   &#x27;transactionDate&#x27;,\n",
              "                                                   &#x27;transactionTime&#x27;,\n",
              "                                                   &#x27;localHour&#x27;,\n",
              "                                                   &#x27;transactionIPaddress&#x27;,\n",
              "                                                   &#x27;digitalItemCount&#x27;,\n",
              "                                                   &#x27;physicalItemCount&#x27;]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
              "                                                                   CategoricalCleaner()),\n",
              "                                                                  (&#x27;onehot&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;transactionCurrencyCode&#x27;,\n",
              "                                                   &#x27;browserLanguage&#x27;,\n",
              "                                                   &#x27;paymentInstrumentType&#x27;,\n",
              "                                                   &#x27;cardType&#x27;,\n",
              "                                                   &#x27;cvvVerifyResult&#x27;])])),\n",
              "                (&#x27;linear_svc&#x27;, LinearSVC(C=1, loss=&#x27;hinge&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
              "                                                                   NumericCleaner()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;transactionAmountUSD&#x27;,\n",
              "                                                   &#x27;transactionDate&#x27;,\n",
              "                                                   &#x27;transactionTime&#x27;,\n",
              "                                                   &#x27;localHour&#x27;,\n",
              "                                                   &#x27;transactionIPaddress&#x27;,\n",
              "                                                   &#x27;digitalItemCount&#x27;,\n",
              "                                                   &#x27;physicalItemCount&#x27;]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
              "                                                                   CategoricalCleaner()),\n",
              "                                                                  (&#x27;onehot&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                                  [&#x27;transactionCurrencyCode&#x27;,\n",
              "                                                   &#x27;browserLanguage&#x27;,\n",
              "                                                   &#x27;paymentInstrumentType&#x27;,\n",
              "                                                   &#x27;cardType&#x27;,\n",
              "                                                   &#x27;cvvVerifyResult&#x27;])])),\n",
              "                (&#x27;linear_svc&#x27;, LinearSVC(C=1, loss=&#x27;hinge&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;cleaner&#x27;, NumericCleaner()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;transactionAmountUSD&#x27;, &#x27;transactionDate&#x27;,\n",
              "                                  &#x27;transactionTime&#x27;, &#x27;localHour&#x27;,\n",
              "                                  &#x27;transactionIPaddress&#x27;, &#x27;digitalItemCount&#x27;,\n",
              "                                  &#x27;physicalItemCount&#x27;]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
              "                                                  CategoricalCleaner()),\n",
              "                                                 (&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;transactionCurrencyCode&#x27;, &#x27;browserLanguage&#x27;,\n",
              "                                  &#x27;paymentInstrumentType&#x27;, &#x27;cardType&#x27;,\n",
              "                                  &#x27;cvvVerifyResult&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;transactionAmountUSD&#x27;, &#x27;transactionDate&#x27;, &#x27;transactionTime&#x27;, &#x27;localHour&#x27;, &#x27;transactionIPaddress&#x27;, &#x27;digitalItemCount&#x27;, &#x27;physicalItemCount&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NumericCleaner</label><div class=\"sk-toggleable__content\"><pre>NumericCleaner()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;transactionCurrencyCode&#x27;, &#x27;browserLanguage&#x27;, &#x27;paymentInstrumentType&#x27;, &#x27;cardType&#x27;, &#x27;cvvVerifyResult&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalCleaner</label><div class=\"sk-toggleable__content\"><pre>CategoricalCleaner()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=1, loss=&#x27;hinge&#x27;)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocess',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('cleaner',\n",
              "                                                                   NumericCleaner()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['transactionAmountUSD',\n",
              "                                                   'transactionDate',\n",
              "                                                   'transactionTime',\n",
              "                                                   'localHour',\n",
              "                                                   'transactionIPaddress',\n",
              "                                                   'digitalItemCount',\n",
              "                                                   'physicalItemCount']),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('cleaner',\n",
              "                                                                   CategoricalCleaner()),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['transactionCurrencyCode',\n",
              "                                                   'browserLanguage',\n",
              "                                                   'paymentInstrumentType',\n",
              "                                                   'cardType',\n",
              "                                                   'cvvVerifyResult'])])),\n",
              "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm_clf = Pipeline((\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))\n",
        "))\n",
        "svm_clf.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model predicting against a single row from the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1613511723457
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.transform called\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_clf.predict(X_test[0:1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, evaluate the model by examining how well it is predicting against all data in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1613511723564
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.transform called\n"
          ]
        }
      ],
      "source": [
        "y_train_preds = svm_clf.predict(X_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use a confusion matrix to see how your model performed when correctly predicting non-fraud and fraud (the top left and bottom right values). Also, examine how your model made mistakes (the bottom left and top right values). In the below, the column headers are predicted non-fraud and predicted fraud, and the row headers are actually non-fraud, and actually fraud (e.g., as described by the training data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1613511723681
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[382, 539],\n",
              "       [112, 808]], dtype=int64)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "confusion_matrix(y_train, y_train_preds)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a look at the performance of your model using the common set of metrics for a classifier. Do you think this is good or bad?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1613511723874
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6463878326996197\n",
            "Precision: 0.5998515219005197\n",
            "Recall: 0.8782608695652174\n",
            "F1: 0.7128363475959418\n",
            "AUC: 0.6465137138271255\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_preds))\n",
        "print(\"Precision:\", precision_score(y_train, y_train_preds))\n",
        "print(\"Recall:\", recall_score(y_train, y_train_preds))\n",
        "print(\"F1:\", f1_score(y_train, y_train_preds))\n",
        "print(\"AUC:\", roc_auc_score(y_train, y_train_preds))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given that this is just a parsimonous model, this model provides a start that performs better than random (as indicated by the AUC being greater than 0.5). There is more work (such as additional feature engineering) that can be done to improve this beyond the current performance that you would want to do before deploying it in production. A parsiminous model helps us to both see if the desired classification is possible given the data and allows to quickly get to something we can deploy as a service to enable integration early on. Then we can iterate deploying improved versions of the model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, evaluate the same using the test data set, using data the trained model has not seen. How does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1613511723990
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.transform called\n",
            "[[ 98 132]\n",
            " [ 34 197]]\n",
            "0.6399132321041214\n",
            "Accuracy: 0.6399132321041214\n",
            "Precision: 0.5987841945288754\n",
            "Recall: 0.8528138528138528\n",
            "F1: 0.7035714285714286\n",
            "AUC: 0.639450404667796\n"
          ]
        }
      ],
      "source": [
        "y_test_preds = svm_clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_test_preds))\n",
        "print(accuracy_score(y_test, y_test_preds))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_preds))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_preds))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_preds))\n",
        "print(\"F1:\", f1_score(y_test, y_test_preds))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_test_preds))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall performance of the model against data it has not seen (the test data) is similar to how it performs with the training data. That's a good sign, indicating we did not overfit the model to the training data.\n",
        "\n",
        "Next, let's look the steps to prepare the model for deployment as a web service."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model to disk\n",
        "\n",
        "In preparation for deploying the model, you need to save the model to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1613511724126
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fraud_score.pkl']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(svm_clf, 'fraud_score.pkl')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test loading the model\n",
        "\n",
        "Next simulate re-loading the model from disk, just like the web service (which you will create in a moment) will have to do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1613511724254
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from customestimators import NumericCleaner, CategoricalCleaner\n",
        "\n",
        "# sklearn.externals.joblib was deprecated in 0.21\n",
        "from sklearn import __version__ as sklearnver\n",
        "from packaging.version import Version\n",
        "if Version(sklearnver) < Version(\"0.21.0\"):\n",
        "    from sklearn.externals import joblib\n",
        "else:\n",
        "    import joblib\n",
        "\n",
        "desired_cols = ['accountID',\n",
        " 'browserLanguage',\n",
        " 'cardType',\n",
        " 'cvvVerifyResult',\n",
        " 'digitalItemCount',\n",
        " 'ipCountryCode',\n",
        " 'ipPostcode',\n",
        " 'ipState',\n",
        " 'isProxyIP',\n",
        " 'localHour',\n",
        " 'paymentBillingCountryCode',\n",
        " 'paymentBillingPostalCode',\n",
        " 'paymentBillingState',\n",
        " 'paymentInstrumentType',\n",
        " 'physicalItemCount',\n",
        " 'transactionAmount',\n",
        " 'transactionAmountUSD',\n",
        " 'transactionCurrencyCode',\n",
        " 'transactionDate',\n",
        " 'transactionID',\n",
        " 'transactionIPaddress',\n",
        " 'transactionTime']\n",
        "\n",
        "scoring_pipeline = joblib.load('fraud_score.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1613511724553
        },
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\catnip\\AppData\\Local\\Temp\\ipykernel_8320\\2496502080.py:1: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  untagged_df_fresh = pd.read_csv('./data/Untagged_Transactions.csv')[desired_cols]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.transform called\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ True,  True, False, ..., False, False, False])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "untagged_df_fresh = pd.read_csv('./data/Untagged_Transactions.csv')[desired_cols]\n",
        "\n",
        "test_pipeline_preds = scoring_pipeline.predict(untagged_df_fresh)\n",
        "test_pipeline_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1613511724654
        },
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumericCleaner.transform called\n",
            "CategoricalCleaner.transform called\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_row = untagged_df_fresh.iloc[:1]\n",
        "test_pipeline_preds2 = scoring_pipeline.predict(one_row)\n",
        "test_pipeline_preds2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2a7a2d454ac7556fd6d46ded514fdcda5ba33f1a47e4241bd3827efe4236550a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
